## 1. 概述

在本教程中，我们将了解分布式系统的基础知识。本文将介绍它们的基本特征、它们所面临的挑战以及常见的解决方案。

我们还将简要介绍一些跨多个类别的流行分布式系统所采用的方法。

## 2. 基本概念

在了解不同系统的分布式架构之前，让我们先了解一些基础知识。

尽管动机在很大程度上影响了分布式架构，但仍有一些基本原则和挑战适用于所有这些架构。

### 2.1. 什么是分布式系统

那么，让我们从正式定义分布式系统开始。分布式系统由多个组件组成，可能跨越地理边界，它们通过消息传递来交流和协调它们的动作。对于这个系统之外的参与者来说，它看起来就像一个单一的连贯系统：

![分布式系统](https://www.baeldung.com/wp-content/uploads/sites/4/2020/12/Distributed-Systems.jpg)

现在我们可能经常听到去中心化系统，把它和分布式系统搞混了。因此，必须做出一些区分。分散式系统是没有特定组件拥有决策权的分布式系统。虽然每个组件都拥有自己的决策部分，但它们都没有完整的信息。因此，任何决策的结果都取决于所有组件之间的某种共识。

与分布式系统密切相关的另一个术语是并行系统。虽然这两个术语都指的是扩大计算能力，但实现它们的方式不同。在并行计算中，我们在一台机器上使用多个处理器同时执行多个任务，可能使用共享内存。然而，在分布式计算中，我们使用多个没有共享内存并通过消息传递进行通信的自治机器。

### 2.2. 分布式系统的好处

虽然分布式系统的设计和构建肯定更复杂，但它带来的好处是值得的。

让我们快速了解一些主要优势：

-   可扩展性：垂直扩展通常受到硬件限制的限制，例如，我们只能拥有这么多处理器内核。然而，理论上我们可以使用相对便宜的商品机器实现无限的水平扩展。
-   可靠性：由于分布式系统由多台机器组成，数据在多个节点上，因此它通常对系统的一部分故障更有弹性。因此，即使容量降低，整个系统也能继续运行。
-   性能：分布式计算的典型应用程序通过将工作负载分解为可以同时在多台机器上运行的较小部分来工作。因此，这极大地提高了许多复杂工作负载的性能，例如矩阵乘法。

### 2.3. 分布式系统中的挑战

如果我们认为我们可以在没有任何挑战的情况下获得分布式系统的所有好处，那么我们就离现实不远了！

让我们了解分布式系统给我们带来的一些关键挑战：

-   Consistency vs. Availability：因为分布式系统根据定义提供分区容错性，它必须在一致性或可用性之间做出选择，如 CAP 定理所约束。对于通用计算平台而言，这不是一个容易的权衡。
-   数据分发：分布式系统中的数据或工作负载需要进行分区以将其发送到多个节点。这就需要复杂的算法来有效地划分并随后组合它们。
-   协调：由于分布式系统中的数据或工作负载也会跨多个节点以实现容错，因此协调它们变得非常棘手。参与节点需要复杂的协议才能就决策达成一致。

往往在企业应用中，我们[需要多个操作在一个事务下发生](https://www.baeldung.com/transactions-intro)。例如，我们可能需要将多个数据更新作为一个工作单元。虽然当数据位于同一位置时这变得微不足道，但当我们将数据分布在节点集群上时它变得相当复杂。许多系统确实使用 Paxos 和 Raft 等复杂协议在分布式环境中提供类似语义的事务。

## 3. 架构与类别

尽管最近对分布式系统的兴趣有所复苏，但其基本原理并不新鲜。很长一段时间以来，分布式系统出现了许多架构模式来解决与数据相关的通用到特定用例。

在本节中，我们将讨论分布式系统的一些架构模式以及它们可以服务的不同类别的用例。

### 3.1. 分布式系统架构

分布式系统的系统架构取决于用例和我们对它的期望。但是，在大多数情况下，我们可以找到一些通用模式。

事实上，这些是架构采用的核心分布模型：

![分布式系统架构模型](https://www.baeldung.com/wp-content/uploads/sites/4/2020/12/Distributed-Systems-Architecture-Models-1024x441-1.jpg)

-   Master-slave：在这种模型中，分布式系统的一个节点扮演master的角色。在这里，主节点拥有关于系统的完整信息并控制决策制定。其余节点充当从节点，执行主节点分配给它们的任务。此外，为了容错，主节点可以有冗余备用。
-   点对点：在此模型中，分布式系统中的节点之间没有指定单个主节点。所有节点均等分担 master 的责任。因此，我们也将其称为多主机或无主机模型。以增加复杂性和通信开销为代价，该模型提供了更好的系统弹性。

虽然这两种架构各有优缺点，但没有必要只选择一种。许多分布式系统实际上创建了一个结合了两种模型元素的体系结构。

对等模型可以提供数据分发，而主从模型可以在同一架构中提供数据。

### 3.2. 分布式系统的类别

设计分布式系统可能有几个基本原理。例如，我们需要在机器学习模型中进行大规模的矩阵乘法等计算。这些不可能容纳在一台机器上。

同样，处理大文件并在一台机器上处理和存储它们的系统可能是不可能的，或者至少是非常低效的。

因此，根据用例，我们可以将分布式系统大致分为以下几类。然而，这绝对不是分布式系统可能用例的详尽列表：

-   数据存储
-   讯息
-   计算
-   账本
-   文件系统
-   应用

传统上，关系数据库在很长一段时间内都是数据存储的默认选择。然而，随着最近数据量、种类和速度的增长，关系数据库开始达不到预期。这就是具有分布式架构的 NoSQL 数据库开始证明更有用的地方。

同样，传统的消息传递系统也无法不受现代数据规模挑战的影响。因此，对可以提供性能、可伸缩性和可能的持久性的分布式消息系统的需求开始上升。今天在这个领域有几个选项可以提供多种语义，比如发布-订阅和点对点。

我们将在本教程中讨论一些流行的分布式数据库和消息系统。重点将主要放在通用架构上，以及它们如何解决分布式系统的一些关键挑战，如分区和协调。

## 4.阿帕奇卡桑德拉

[Cassandra](https://www.baeldung.com/cassandra-with-java)是一个开源的分布式键值系统，采用分区宽列存储模型。它具有完整的多主数据功能，可提供高可用性和低延迟。它是线性可扩展的，没有单点故障。

Cassandra支持高可用性和可伸缩性，因此是最终一致的数据库。这实质上意味着对数据的所有更新最终都会到达所有副本。但是，相同数据的不同版本可以暂时存在。但是，Cassandra 还以可供选择的一致性级别列表的形式为读取和写入操作提供可调一致性。

### 4.1. 数据分布

Cassandra 通过在集群中的节点间均匀划分所有数据来提供水平扩展。跨集群分布数据的一种简单方法是使用分布式哈希表。但是，如果集群中的节点数量发生变化，它们通常会受到重新散列的影响。这就是一致性哈希被证明更好并因此被 Cassandra 使用的地方。

一致性哈希是一种独立于集群中节点数的分布式哈希方案。它有一个抽象环的概念，代表哈希值的总范围，也称为令牌：

![Cassandra 令牌环](https://www.baeldung.com/wp-content/uploads/sites/4/2020/12/Cassandra-Token-Ring-1024x642.jpg)

Cassandra 将集群中的每个节点映射到此令牌环上的一个或多个令牌，以便整个令牌范围均匀分布在集群中。因此，每个节点都拥有这个环中的一系列令牌，具体取决于我们将它们放置在环中的位置。

为了确定密钥的所有权，Cassandra 首先通过对密钥进行散列来生成令牌。它使用分区器作为哈希函数，而 Murmur3Partitioner 是默认的分区器。一旦它在环上找到密钥的令牌，它就会沿顺时针方向遍历环以识别拥有该令牌并因此拥有密钥的最近节点。

现在，Cassandra还跨多个物理节点每个分区以提供容错能力。它支持可插拔策略，如 Siple 策略和网络拓扑策略，以确定哪些节点充当给定令牌范围的副本。对于 Simple Strategy，它只是不断地走环，直到它找到由因子 (RF) 定义的不同节点的数量。

### 4.2. 协调

由于Cassandra集群是多主的，集群中的每个节点都可以独立的接受读写操作。接收请求的节点充当应用程序的代理。我们称代理节点为协调器，负责使用分区器识别拥有密钥的节点。

因此，每个节点都需要知道集群中哪些节点是活的还是死的，以优化路由操作。Cassandra 使用 Gossip 协议在集群中传播基本的集群引导信息：

![卡桑德拉八卦](https://www.baeldung.com/wp-content/uploads/sites/4/2020/12/Cassandra-Gossip.jpg)

Gossip 是一种点对点通信协议，其中每个节点定期与其他几个节点交换状态信息。他们交换关于他们自己和他们知道的其他节点的信息。此外，它使用矢量时钟对信息进行版本化，以便八卦可以忽略集群状态的旧版本。

多主架构的另一个问题是多个副本可以同时接受相同的密钥变更请求。因此，必须有一种机制来协调跨副本集的并发更新。

Cassandra 使用 Last-Write-Wins 模型来解决这个问题。为了简化它，在这里，每个突变都带有时间戳，并且最新版本总是获胜。

## 5. MongoDB

[MongoDB](https://www.baeldung.com/java-mongodb)是一种开源、通用、基于文档的分布式数据库，将数据存储为文档集合。文档是由字段和值对组成的简单数据结构。此外，它还提供用于复杂数据建模的嵌入式文档和数组。

我们可以将 MongoDB 分片部署为副本集。副本集的主要成员处理所有请求。在自动故障转移期间，分片通常无法处理请求。这使得 MongoDB 默认情况下具有强一致性。但是，为了实现高可用性，客户端可以选择从数据最终保持一致的辅助副本读取数据。

### 5.1. 数据分布

MongoDB 使用分片键将集合中的文档分布到多个分片中。我们可以从文档中的一个或多个字段创建分片键。显然，shard key 的选择意味着分片集群的性能、效率和可扩展性。

MongoDB 使用分片键将数据分成块。它试图在集群中的所有分片中实现块的均匀分布：

![MongoDB 分片 1](https://www.baeldung.com/wp-content/uploads/sites/4/2020/12/MongoDB-Sharding-1.jpg)

MongoDB支持两种分片策略，散列分片和范围分片。使用散列分片，它计算分片键值的散列值并将散列值范围分配给每个块。通过范围分片，MongoDB 根据分片键值将数据划分为范围，并为每个块分配一个范围。

平衡分片中块的分布也很重要。MongoDB 中的默认块大小为 64 兆字节。当块增长超过指定的大小限制或超过配置限制的文档数量时，MongoDB 会根据分片键值拆分块。此外，MongoDB运行一个平衡器进程，自动在分片之间迁移块以实现均匀分布。

为了改进数据局部性，MongoDB 提供了区域的概念。当分片跨越多个数据中心时，这尤其有用。在分片集群中，我们可以根据分片键创建区域。此外，我们可以将每个区域与集群中的一个或多个分片相关联。因此，MongoDB 只会将区域覆盖的块迁移到与该区域关联的那些分片。

### 5.2. 协调

MongoDB 使用分片作为跨多台机器分布数据的方法。因此，MongoDB 的分片集群是可水平扩展的。一个分片包含数据的一个子集，每个分片可以部署为一个副本集。该集群还包括 mongos、查询路由器和用于存储元数据和配置设置的配置服务器：

![MongoDB集群](https://www.baeldung.com/wp-content/uploads/sites/4/2020/12/MongoDB-Cluster.jpg)

副本集在 MongoDB 中提供自动故障转移和数据冗余。正如我们在上面看到的，副本集是一组维护相同数据集的 mongod 实例。主服务器通过将它们记录在称为 oplog 的操作日志中来处理所有写操作。然后辅助节点异步主节点的操作日志。

当 primary 在配置的时间内没有与 secondary 通信时，符合条件的 secondary 可以通过选举来提名自己作为新的 primary。除了主要和次要之外，我们还可以有额外的 mongod 实例，称为仲裁器，它参与选举但不保存数据。集群尝试完成新主节点的选举。

这确实为 MongoDB 中的数据丢失留下了空间，但我们可以通过选择适当的写入关注点来最小化它。写入关注是我们从 MongoDB请求的确认级别。“多数”的写关注意味着我们请求确认写操作已经传播到计算出的大多数数据承载投票成员。

## 6. 雷迪斯

[Redis](https://www.baeldung.com/spring-data-redis-tutorial)是一种开源数据结构存储，我们可以将其用作数据库、缓存甚至消息代理。它支持不同类型的数据结构，例如字符串、列表、映射等等。它主要是一个内存中的键值存储，具有可选的持久性。

Redis 使用主从架构提供高可用性，其中从属是主的精确副本。主节点接受来自客户端的写请求。它进一步异步地将写入到从节点。但是，客户端可以使用 WAIT 命令请求同步。因此，Redis 更倾向于可用性和性能而不是强一致性。

### 6.1. 数据分布

Redis将数据划分为多个实例以从水平缩放中获益。它提供了几种替代机制来对数据进行分区，包括范围分区和散列分区。现在，范围分区很简单，但使用起来效率不高。相反，散列分区被证明更有效。

散列分区的基本前提很简单。我们可以获取密钥并使用任何标准哈希函数(如 CRC32)来生成密钥的哈希值，它只是一个数字。然后我们对哈希进行取模运算，得到这个key可以映射到的实例。显然，这有一定的局限性，一致性哈希性能更好。

现在，可以在 Redis 软件堆栈的不同部分进行分区。从客户端开始，一些 Redis 客户端实现了客户端分区。然后我们有基于代理的分区，其中像 Twemproxy 这样的代理处理分区：

![Redis实例](https://www.baeldung.com/wp-content/uploads/sites/4/2020/12/Redis-Instances.jpg)

在这里，Redis Sentinel 通过在实例或分片内提供自动故障转移来提供高可用性。最后，我们还可以使用查询路由，集群中的任何随机实例都可以通过将请求路由到正确的节点来处理请求。

Redis Cluster 允许自动分区和高可用性，因此是实现相同目标的首选方法。它混合使用查询路由和客户端分区。Redis 集群使用一种分片形式，其中每个键都是哈希槽的一部分。Redis 集群中有 16384 个哈希槽，每个节点负责其中的一个子集。

### 6.2. 协调

Redis Cluster 是 Redis 的分布式实现，具有高性能目标、线性可伸缩性、高可用性和可接受的写入安全度。它遵循由多个主站和从站组成的主动-被动架构：

![Redis集群](https://www.baeldung.com/wp-content/uploads/sites/4/2020/12/Redis-Cluster-1024x449.jpg)

Redis 集群中的节点负责保存数据、将键映射到正确的节点、检测集群中的其他节点，并在需要时将从属节点提升为主节点。为了完成所有这些任务，Redis 集群中的每个节点都通过 TCP 总线和称为 Redis 集群总线的二进制协议连接。此外，节点使用八卦协议传播有关集群的信息。

由于 Redis 集群使用异步，因此需要针对故障提供合理的写入安全性。Redis Cluster 使用最后一次故障转移胜出的隐式合并功能。这意味着最后选出的主数据集最终会取代所有其他副本。这会留下一小段时间，可能会在分区期间丢失写入。但是，Redis 尽最大努力保留客户端在连接到大多数主服务器时执行的写入。

Redis 集群不会将命令代理到正确的节点。相反，它们将客户端重定向到为键空间的给定部分提供服务的正确节点。客户端可以自由地向所有集群节点发送请求，并在需要时进行重定向。但是，最终，客户端会收到有关集群的最新信息，并可以直接联系正确的节点。

## 7.阿帕奇卡夫卡

[Kafka](https://www.baeldung.com/spring-kafka)是一个开源平台，旨在提供统一、高吞吐量、低延迟的系统来处理实时数据馈送。它允许我们发布和订阅事件流，持久可靠地存储事件流，并在事件流发生或追溯时对其进行处理。

为了增强持久性和可用性，Kafka 通过自动故障转移跨多个节点数据。只有当所有同步副本都使用了事件时，事件才被视为已提交。此外，只有承诺的消费者才能接收消息。因此，Kafka 被设计成高度一致和可用的，有许多配置可供使用。

### 7.1. 数据分布

Kafka 在主题中组织和持久存储事件。生产者是向主题发布事件的应用程序，消费者是从主题订阅事件的应用程序。我们可以将每个主题划分为一个或多个分区，并将它们分布在不同的节点上以实现可扩展性。这也允许多个消费者并行地从一个主题中读取数据：

![Kafka 主题分区](https://www.baeldung.com/wp-content/uploads/sites/4/2020/12/Kafka-Topic-Partition-1024x546.jpg)

这里的分区简单的说，从生产者的角度来看就是一个以追加方式工作的commit log。分区中的每个事件都有一个称为偏移量的标识符，它唯一地标识事件在提交日志中的位置。此外，Kafka 在可配置的时间段内保留主题中的事件。

生产者可以控制将事件发布到哪个分区。它可以是可用分区之间的随机负载平衡或使用一些语义分区功能。我们可以定义一个分区键，Kafka 可以使用它来将事件散列到固定分区。这导致分区中事件的位置可能对消费者很重要。

消费者可以选择从任何偏移点读取事件。Kafka 中的消费者组在逻辑上将多个消费者分组以负载平衡主题分区的消费。Kafka 仅将主题分区分配给消费者组中的一个消费者。当组中的消费者数量发生变化时，Kafka 会自动尝试重新平衡消费者之间的分区分配。

### 7.2. 协调

Kafka 集群通常由多个服务器组成，这些服务器可以跨越多个数据中心或云区域。它们相互通信，并使用高性能 TCP 网络协议与客户端通信。我们将保存数据作为主题分区的服务器称为代理。每个经纪人拥有几个分区。

此外，Kafka 使用 ZooKeeper 来存储元数据，例如分区的位置和主题的配置：

![卡夫卡集群](https://www.baeldung.com/wp-content/uploads/sites/4/2020/12/Kafka-Cluster-1024x533-1.jpg)

正如我们所见，Kafka 还跨可配置数量的代理每个主题分区的日志。对主题的所有写入和读取都经过分区的领导者。领导者协调以使用新数据更新副本。万一领导者失败，其中一个副本将通过自动故障转移接管领导者的角色。

如果 Kafka 可以保持与 ZooKeeper 的会话并且不会落后于领导者太远，则它会将副本定义为同步副本 (ISR)。在所有同步副本都收到写入之前，不会将对 Kafka 的写入视为已提交。此外，只有同步副本集合中的成员才有资格被选为领导者。因此，Kafka 可以容忍除了一个同步副本之外的所有副本失败而不会丢失提交的数据。

根据我们配置和使用 Kafka 客户端的方式，我们可以实现不同的消息传递语义。例如，至多一次、至少一次或恰好一次。在生产者端，我们可以通过配置生产者的acks属性和代理的min.insync.replica属性来实现不同的交付语义。同样，在消费者方面，我们可以使用像enable.auto.commit这样的配置来控制交付语义。

## 8. CAP 定理的注释

Eric Brewer 假设 CAP 定理根据分布式系统可以保证的属性来定义对分布式系统的约束。基本上，这意味着分布式系统不能同时提供以下三个保证中的两个以上：

-   一致性：每次读取都会收到最近的写入或错误
-   可用性：每次读取都会收到一个非错误响应，即使它可能不是最近的写入
-   分区容错：即使部分网络出现故障，系统仍可继续运行

![CAP定理](https://www.baeldung.com/wp-content/uploads/sites/4/2020/12/CAP-Theorem.jpg)

以上，我们可以看到 CAP 定理如何被用作对分布式系统进行分类的指路明灯！但这种分类往往过于简单化，可能被误导，而且在某种程度上也是不必要的。

现在，在分布式系统中几乎不可能完全消除网络分区的可能性。因此，基本上，CAP 定理的含义归结为在一致性或可用性之间进行权衡。所以一个号称分布式的系统和CA必须对其运行所在的网络有坚定的信心。

但是，正如我们在前面讨论的几个分布式系统的上下文中看到的那样，这确实不是一个容易的选择。因此，这些系统中的大多数在配置中提供了很多控制，以便我们可以选择行为作为标准要求。因此，将这些系统简单地归类为 CP 或 AP 是不公平的，甚至是不正确的。

## 9.总结

在本教程中，我们了解了分布式系统的基础知识并了解了主要优势和挑战。此外，我们对一些跨数据存储和消息系统的流行分布式系统进行了广泛评估。

我们强调了它们如何在分布式架构中实现数据分发和协调。