## 1. 概述

在本教程中，我们将分析使我们能够构建复杂的中央处理器单元 ( [CPU](https://www.baeldung.com/cs/cpu-guide) ) 的复杂想法。尽管我们使用[寄存器](https://www.baeldung.com/cs/registers-and-ram)、[算术逻辑单元](https://www.baeldung.com/cs/arithmetic-logic-unit)和控制单元来抽象 CPU，但它还有一些其他复杂的部分，例如缓存和指令流水线、分支预测等高级机制。

## 2.简介

我们正在撰写和发布这些文章的设备可能以千兆赫兹的速度运行。那是每秒执行十亿条指令。当我们想到每秒只执行一次计算的早期计算机时，我们可以理解计算机从那时起已经走了很长一段路。

在计算的早期，处理器设计者通常习惯于尝试改善晶体管的切换时间或增加芯片内部晶体管的数量。然而，由于晶体管和芯片的性质限制，处理器设计人员开发了不同的机制来提高性能。

CPU 甚至可以通过指令执行最微小的计算。例如，要除两个数，它可以将此操作分解为更小的减法问题。它不断地从另一个数中提取一个数，直到它达到零或负数。这种方法消耗了大量的时钟周期。

今天，大多数计算机处理器都具有 ALU 可以在硬件中执行的除法指令。尽管它使 ALU 变得更大、更复杂，但它是一种有用的复杂性与速度的权衡，在计算历史上多次被首选。

除了这条除法指令之外，还有一些专门的 CPU，它们具有用于加密文件、解码压缩视频和图形操作等特定电路。例如，Intel 的 MMX 和 AMD 的 3DNow! 下图中是一些专用 CPU 的示例：

![3dnow](https://www.baeldung.com/wp-content/uploads/sites/4/2021/09/3dnow-300x258-1.gif)![英特尔MMX](https://www.baeldung.com/wp-content/uploads/sites/4/2021/09/intel_mmx-300x300-1.jpg)

这些指令集的扩展随着时间的推移而增长。当人们利用这些说明时，很难将其删除。因此，指令集往往会变得越来越大，以保留所有操作码。最早的 CPU 之一，[英特尔 4004](https://en.wikipedia.org/wiki/Intel_4004)，只有 46 条指令，足以构建功能齐全的计算机，如[Kenbak-1](https://en.wikipedia.org/wiki/Kenbak-1)。

### 2.1. 现代处理器的瓶颈

现代计算机处理器有数以千计的各种指令。他们利用各种复杂的内部电路。这些奇特的指令集和高时钟速度导致了另一个问题。它足够快地从 CPU 中获取数据。想象一下，我们有一家家具厂，可以在几秒钟内生产出这么多产品。工厂里一直需要很多木材。

此时，瓶颈是RAM。它是位于 CPU 之外的内存模块。想象一下，对于我们的家具厂类比来说，它是城外的一片森林。这意味着数据应该与数据线一起从 RAM 传输到 RAM，称为总线。

这辆公共汽车只有几厘米。尽管电信号以接近光速的速度传播，但当以千兆赫兹的速度(即十亿分之一秒)工作时，即使是微小的延迟也会带来麻烦。RAM 还需要时间来搜索地址和检索数据。因此从 RAM 加载可能需要数百个时钟周期。如果我们回到我们的类比，如果同时尝试从森林中获取木材，工厂将无能为力，因为它没有木材来制造家具。同样，CPU 只是闲置在那里等待数据。

## 3.缓存

克服这个瓶颈的一个解决方案是在 CPU 上放置一小块存储单元。它被称为缓存。从下图中我们可以看出，处理器芯片上的面积并不大。因此，大多数缓存的大小仅为千字节或兆字节，而 RAM 为千兆字节。如果我们再想想我们的类比，它就像是一个仓库，供树林用来建造家具。我们可以将其存放在工厂附近的仓库中，而不是等待来自森林的木材。这样，我们可以巧妙地加快这个过程：

![缓存](https://www.baeldung.com/wp-content/uploads/sites/4/2021/09/cache.png)

每当 CPU 从 RAM 请求内存位置时，RAM 不仅可以发送一个值，还可以发送一整块数据。这比发送单个值花费的时间稍长，但它允许将此数据块存储在缓存中。这是非常有益的，因为计算机存储经常连续组织和处理的数据。

当处理器在计算一些表达式时，它不需要一路走到 RAM。由于高速缓存非常靠近处理器，它通常可以在单个时钟周期内提供数据。重新思考我们的类比，我们可以直接使用仓库中的资源，即处理器中的缓存，而不是一路走到森林。

### 3.1. 缓存命中、缓存未命中和脏位

如果从 RAM 请求的数据已经在缓存中，我们称之为缓存命中。如果请求的数据不在缓存中，我们必须一直到 RAM，我们称之为缓存未命中。

将数据放在两个不同的地方可能会导致同步问题。当我们更改缓存中地址的值时，我们也需要在 RAM 中更新它。为此，缓存为其存储的每个内存块都有一个标志。它被称为脏位。大多数情况下，这种同步发生在缓存已满时。在缓存擦除旧块以释放空间之前，它会检查其脏位。如果脏了，旧的数据块将被写回 RAM。


## 4. 指令流水线

指令流水线是 CPU 设计者用来提高 CPU 吞吐量的另一种机制。让我们回到我们有一家家具公司的类比，所以为了制造家具，我们需要一些正确的操作。就像得到木头，把木头切成碎片，然后以某种方式组装起来。我们可以将它们并行化，而不是单独获取所有木材并切割所有木材过程。

就像在家具示例中一样，CPU 应该遵循简单地包含、获取、解码和执行的[指令周期。](https://www.baeldung.com/cs/cpu-guide#2-instruction-cycle)我们可以完成所有三个阶段，然后开始新的循环。然而，在获取第一条指令之后我们还有另一个选择：我们可以获取另一条指令。由于每个阶段使用 CPU 的不同部分，我们可以将它们并行化。

让我们看看下图以更好地理解。正如我们所见，为了获取第二条指令，我们正在等待第一条指令执行：

![没有管道](https://www.baeldung.com/wp-content/uploads/sites/4/2021/09/no-pipeline-1024x207-1.png)

但是，在执行一条指令时，可以解码下一条指令。所有这些单独的进程都可以重叠，因此 CPU 的所有部分在任何给定时间都处于活动状态。通过下图中的这种设计，我们可以将吞吐量提高三倍：

![管道](https://www.baeldung.com/wp-content/uploads/sites/4/2021/09/pipeline-1024x360-1.png)

### 4.1. 指令依赖

指令之间可能存在依赖关系。例如，我们可能会获取一些即将被另一条指令更改的内容。在这种情况下，我们最终会在管道中使用旧值。

为了恢复这种情况，流水线处理器必须提前查找数据依赖性，如果有，则停止它们的流水线以消除问题。笔记本电脑和智能手机中的专用和复杂处理器可以动态地重新排序具有依赖关系的指令，以减少停顿并保持流水线畅通。我们称之为乱序执行。

### 4.2. 推测执行和分支预测器

另一个问题是条件跳转条件。这些指令可以根据值改变程序的执行路径。

当一个基本的流水线处理器检测到一个跳转指令时，它会在等待值完成时执行一个长时间的停顿。处理器只有在知道跳转结果时才开始重新填充其管道。但是，这可能会导致严重延迟。因此高端处理器有各种技术来处理这个问题。

考虑即将到来的跳转指令，一个分支。高级 CPU 估计它们将继续执行哪条路径，并根据该假设开始使用指令加载它们的管道。我们称这种技术为推测执行。

如果这些估计是错误的，CPU 必须丢弃所有推测结果并执行刷新。为了减少这些刷新的影响，CPU 设计者开发了特殊的方法来猜测分支将去哪里。这称为分支预测。现代处理器的分支预测器的准确性已经提高并超过了 50/50 的猜测。然而，这种排他性的设计方法可能会导致被称为[推测执行侧信道漏洞](https://en.wikipedia.org/wiki/Spectre_(security_vulnerability))的安全问题。

## 5. 超标量处理器和多核处理器

超标量处理器每个时钟周期可以执行多条指令，如下图所示。即使在流水线设计中，在执行阶段，CPU 的某些区域也可能完全空闲。例如，当执行一条从内存中取值的指令时，ALU 将处于空闲状态。

超标量处理器了流行指令的电路。它没有单独的处理器或内核。它利用单个 CPU(例如 ALU)中的执行资源：

![超标量](https://www.baeldung.com/wp-content/uploads/sites/4/2021/09/superscalar-1024x740-1.png)

另一种提高性能的方法是使用多核处理器同时运行许多指令流。双核或四核处理器是单个 CPU 芯片内部多个独立处理单元的示例，如下图所示。它代表了2008 年发布[的下一代英特尔微架构 (Nehalem)](https://ieeexplore.ieee.org/document/4585952)的核心结构。它还有其他一些重要的部分，但是在本文的范围内我们不打算详细介绍它们：

![尼哈勒姆某处](https://www.baeldung.com/wp-content/uploads/sites/4/2021/09/nehalem_somepart.png)

## 六，总结

在本文中，我们简要解释了高级 CPU 的复杂部件和机制。我们分享了一个关于缓存的类比，以使事情更容易理解。我们还解释了指令流水线并研究了超标量和多核处理器的工作原理。